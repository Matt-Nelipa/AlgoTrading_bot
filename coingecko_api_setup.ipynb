{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tti.indicators as ti  # Импорт всех индикаторов\n",
    "import inspect\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer, root_mean_squared_error, mean_absolute_percentage_error\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tensorflow.keras.optimizers import AdamW # type: ignore\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Загружаем переменные из .env файла\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "\n",
    "url = 'https://api.coingecko.com/api/v3/coins/bitcoin/market_chart'\n",
    "\n",
    "headers = {\"accept\": \"application/json\",\n",
    "    \"x-cg-api-key\": api_key}\n",
    "\n",
    "# Параметры запроса\n",
    "params = {\n",
    "    'vs_currency': 'usd',  # Валюта для отображения цены (например, USD)\n",
    "    'days': '365',         # Данные за последний год\n",
    "    'interval': 'daily'    # Получение данных на ежедневной основе\n",
    "}\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1697932800000, 29677.0, 30253.0, 29484.0, 29920.0],\n",
       " [1698278400000, 29920.0, 35066.0, 29741.0, 34472.0],\n",
       " [1698624000000, 34498.0, 34819.0, 33450.0, 34556.0],\n",
       " [1698969600000, 34525.0, 35878.0, 34108.0, 34924.0],\n",
       " [1699315200000, 34937.0, 35366.0, 34123.0, 35031.0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters\n",
    "coin_id = 'bitcoin'\n",
    "vs_currency = 'usd'\n",
    "days = '365'\n",
    "\n",
    "# Make the API request\n",
    "url_ohlc = f'https://api.coingecko.com/api/v3/coins/{coin_id}/ohlc?vs_currency={vs_currency}&days={days}'\n",
    "response = requests.get(url_ohlc, headers=headers)\n",
    "ohlc_data = response.json()\n",
    "ohlc_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>29677.0</td>\n",
       "      <td>30253.0</td>\n",
       "      <td>29484.0</td>\n",
       "      <td>29920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>29920.0</td>\n",
       "      <td>35066.0</td>\n",
       "      <td>29741.0</td>\n",
       "      <td>34472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>34498.0</td>\n",
       "      <td>34819.0</td>\n",
       "      <td>33450.0</td>\n",
       "      <td>34556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>34525.0</td>\n",
       "      <td>35878.0</td>\n",
       "      <td>34108.0</td>\n",
       "      <td>34924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>34937.0</td>\n",
       "      <td>35366.0</td>\n",
       "      <td>34123.0</td>\n",
       "      <td>35031.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp     open     high      low    close\n",
       "0 2023-10-22  29677.0  30253.0  29484.0  29920.0\n",
       "1 2023-10-26  29920.0  35066.0  29741.0  34472.0\n",
       "2 2023-10-30  34498.0  34819.0  33450.0  34556.0\n",
       "3 2023-11-03  34525.0  35878.0  34108.0  34924.0\n",
       "4 2023-11-07  34937.0  35366.0  34123.0  35031.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['timestamp', 'open', 'high', 'low', 'close']\n",
    "\n",
    "df_ohlc = pd.DataFrame(ohlc_data, columns=columns)\n",
    "df_ohlc.timestamp = pd.to_datetime(df_ohlc.timestamp, unit='ms')\n",
    "df_ohlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>total_volumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>7.452489e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>1.133030e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>3.555886e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>4.646471e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>2.384046e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  total_volumes\n",
       "0 2023-10-22   7.452489e+09\n",
       "1 2023-10-23   1.133030e+10\n",
       "2 2023-10-24   3.555886e+10\n",
       "3 2023-10-25   4.646471e+10\n",
       "4 2023-10-26   2.384046e+10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем список для хранения отформатированных данных\n",
    "formatted_data = []\n",
    "\n",
    "# Извлекаем данные\n",
    "for i in range(len(data[\"prices\"])):\n",
    "    # Извлекаем timestamp (одинаковый для всех ключей)\n",
    "    timestamp = data[\"prices\"][i][0]\n",
    "    \n",
    "    # Переводим метку времени из миллисекунд в секунды\n",
    "    timestamp_in_seconds = timestamp / 1000\n",
    "    \n",
    "    # Преобразуем timestamp в объект даты\n",
    "    date = datetime.datetime.fromtimestamp(timestamp_in_seconds).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Извлекаем уникальные значения для каждого ключа\n",
    "    price = data[\"prices\"][i][1]\n",
    "    market_cap = data[\"market_caps\"][i][1]\n",
    "    total_volumes = data[\"total_volumes\"][i][1]\n",
    "    \n",
    "    # Добавляем отформатированные данные в список\n",
    "    formatted_data.append([date, price, market_cap, total_volumes])\n",
    "\n",
    "# Создаем DataFrame с колонками \"timestamp\", \"price\", \"market_cap\", \"total_volumes\"\n",
    "df = pd.DataFrame(formatted_data, columns=['timestamp', 'prices', 'market_caps', 'total_volumes'])\n",
    "df.timestamp = pd.to_datetime(df.timestamp)\n",
    "df = df.iloc[:, [0, -1]]\n",
    "# Выводим DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-20</th>\n",
       "      <td>67103.0</td>\n",
       "      <td>68970.0</td>\n",
       "      <td>66739.0</td>\n",
       "      <td>68389.0</td>\n",
       "      <td>1.411089e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>62465.0</td>\n",
       "      <td>67803.0</td>\n",
       "      <td>62060.0</td>\n",
       "      <td>66962.0</td>\n",
       "      <td>5.179793e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-12</th>\n",
       "      <td>62211.0</td>\n",
       "      <td>63362.0</td>\n",
       "      <td>58935.0</td>\n",
       "      <td>62392.0</td>\n",
       "      <td>3.200866e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>60749.0</td>\n",
       "      <td>64500.0</td>\n",
       "      <td>60470.0</td>\n",
       "      <td>62287.0</td>\n",
       "      <td>3.387888e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04</th>\n",
       "      <td>65603.0</td>\n",
       "      <td>65603.0</td>\n",
       "      <td>59954.0</td>\n",
       "      <td>60728.0</td>\n",
       "      <td>3.771114e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close        volume\n",
       "date                                                        \n",
       "2024-10-20  67103.0  68970.0  66739.0  68389.0  1.411089e+10\n",
       "2024-10-16  62465.0  67803.0  62060.0  66962.0  5.179793e+10\n",
       "2024-10-12  62211.0  63362.0  58935.0  62392.0  3.200866e+10\n",
       "2024-10-08  60749.0  64500.0  60470.0  62287.0  3.387888e+10\n",
       "2024-10-04  65603.0  65603.0  59954.0  60728.0  3.771114e+10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(df_ohlc, df[:365], on='timestamp', how='inner')\n",
    "df_final = df_final.rename(columns={'timestamp':'date', 'total_volumes':'volume'}).set_index('date').sort_index(ascending=False)\n",
    "df_final_copy = df_final.copy()\n",
    "df_final_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do\n",
    "- try log \n",
    "- try data sampling \n",
    "- try forecast target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adl</th>\n",
       "      <th>middle_band</th>\n",
       "      <th>upper_band</th>\n",
       "      <th>lower_band</th>\n",
       "      <th>cmf</th>\n",
       "      <th>...</th>\n",
       "      <th>tp</th>\n",
       "      <th>uosc</th>\n",
       "      <th>vhf</th>\n",
       "      <th>vch</th>\n",
       "      <th>vosc</th>\n",
       "      <th>vrc</th>\n",
       "      <th>wc</th>\n",
       "      <th>ws</th>\n",
       "      <th>wad</th>\n",
       "      <th>wr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>62465.0</td>\n",
       "      <td>67803.0</td>\n",
       "      <td>62060.0</td>\n",
       "      <td>66962.0</td>\n",
       "      <td>5.179793e+10</td>\n",
       "      <td>361902942122</td>\n",
       "      <td>61053.70</td>\n",
       "      <td>66929.4047</td>\n",
       "      <td>55177.9953</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>...</td>\n",
       "      <td>65608.3333</td>\n",
       "      <td>59.0712</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>-11.2464</td>\n",
       "      <td>8.234233e+09</td>\n",
       "      <td>98.5535</td>\n",
       "      <td>65946.75</td>\n",
       "      <td>62896.2072</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>-9.4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-12</th>\n",
       "      <td>62211.0</td>\n",
       "      <td>63362.0</td>\n",
       "      <td>58935.0</td>\n",
       "      <td>62392.0</td>\n",
       "      <td>3.200866e+10</td>\n",
       "      <td>325275499076</td>\n",
       "      <td>61108.35</td>\n",
       "      <td>67218.5053</td>\n",
       "      <td>54998.1947</td>\n",
       "      <td>-0.1120</td>\n",
       "      <td>...</td>\n",
       "      <td>61563.0000</td>\n",
       "      <td>55.9873</td>\n",
       "      <td>0.5272</td>\n",
       "      <td>-19.7979</td>\n",
       "      <td>4.416763e+09</td>\n",
       "      <td>147.3988</td>\n",
       "      <td>61770.25</td>\n",
       "      <td>61879.7590</td>\n",
       "      <td>3457.0</td>\n",
       "      <td>-53.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>60749.0</td>\n",
       "      <td>64500.0</td>\n",
       "      <td>60470.0</td>\n",
       "      <td>62287.0</td>\n",
       "      <td>3.387888e+10</td>\n",
       "      <td>307293674868</td>\n",
       "      <td>61285.85</td>\n",
       "      <td>67731.8764</td>\n",
       "      <td>54839.8236</td>\n",
       "      <td>-0.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>62419.0000</td>\n",
       "      <td>57.4873</td>\n",
       "      <td>0.3999</td>\n",
       "      <td>-24.7038</td>\n",
       "      <td>1.108212e+10</td>\n",
       "      <td>-0.9134</td>\n",
       "      <td>62386.00</td>\n",
       "      <td>61751.6988</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>-57.4512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04</th>\n",
       "      <td>65603.0</td>\n",
       "      <td>65603.0</td>\n",
       "      <td>59954.0</td>\n",
       "      <td>60728.0</td>\n",
       "      <td>3.771114e+10</td>\n",
       "      <td>310622715799</td>\n",
       "      <td>61506.00</td>\n",
       "      <td>68361.5014</td>\n",
       "      <td>54650.4986</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>...</td>\n",
       "      <td>62095.0000</td>\n",
       "      <td>60.8172</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>-20.0747</td>\n",
       "      <td>5.545745e+08</td>\n",
       "      <td>18.1436</td>\n",
       "      <td>61753.25</td>\n",
       "      <td>61617.8734</td>\n",
       "      <td>-4936.0</td>\n",
       "      <td>-64.3131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>63146.0</td>\n",
       "      <td>66439.0</td>\n",
       "      <td>62812.0</td>\n",
       "      <td>65664.0</td>\n",
       "      <td>1.294871e+10</td>\n",
       "      <td>337999840733</td>\n",
       "      <td>61711.35</td>\n",
       "      <td>68705.9634</td>\n",
       "      <td>54716.7366</td>\n",
       "      <td>0.4622</td>\n",
       "      <td>...</td>\n",
       "      <td>64971.6667</td>\n",
       "      <td>65.5435</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>-23.6821</td>\n",
       "      <td>-4.098893e+09</td>\n",
       "      <td>-63.6838</td>\n",
       "      <td>65144.75</td>\n",
       "      <td>61840.3418</td>\n",
       "      <td>2852.0</td>\n",
       "      <td>-7.1323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close        volume           adl  \\\n",
       "date                                                                         \n",
       "2024-10-16  62465.0  67803.0  62060.0  66962.0  5.179793e+10  361902942122   \n",
       "2024-10-12  62211.0  63362.0  58935.0  62392.0  3.200866e+10  325275499076   \n",
       "2024-10-08  60749.0  64500.0  60470.0  62287.0  3.387888e+10  307293674868   \n",
       "2024-10-04  65603.0  65603.0  59954.0  60728.0  3.771114e+10  310622715799   \n",
       "2024-09-30  63146.0  66439.0  62812.0  65664.0  1.294871e+10  337999840733   \n",
       "\n",
       "            middle_band  upper_band  lower_band     cmf  ...          tp  \\\n",
       "date                                                     ...               \n",
       "2024-10-16     61053.70  66929.4047  55177.9953  0.1860  ...  65608.3333   \n",
       "2024-10-12     61108.35  67218.5053  54998.1947 -0.1120  ...  61563.0000   \n",
       "2024-10-08     61285.85  67731.8764  54839.8236 -0.1993  ...  62419.0000   \n",
       "2024-10-04     61506.00  68361.5014  54650.4986 -0.0346  ...  62095.0000   \n",
       "2024-09-30     61711.35  68705.9634  54716.7366  0.4622  ...  64971.6667   \n",
       "\n",
       "               uosc     vhf      vch          vosc       vrc        wc  \\\n",
       "date                                                                     \n",
       "2024-10-16  59.0712  0.4556 -11.2464  8.234233e+09   98.5535  65946.75   \n",
       "2024-10-12  55.9873  0.5272 -19.7979  4.416763e+09  147.3988  61770.25   \n",
       "2024-10-08  57.4873  0.3999 -24.7038  1.108212e+10   -0.9134  62386.00   \n",
       "2024-10-04  60.8172  0.4822 -20.0747  5.545745e+08   18.1436  61753.25   \n",
       "2024-09-30  65.5435  0.5498 -23.6821 -4.098893e+09  -63.6838  65144.75   \n",
       "\n",
       "                    ws     wad       wr  \n",
       "date                                     \n",
       "2024-10-16  62896.2072  4902.0  -9.4835  \n",
       "2024-10-12  61879.7590  3457.0 -53.9312  \n",
       "2024-10-08  61751.6988  1817.0 -57.4512  \n",
       "2024-10-04  61617.8734 -4936.0 -64.3131  \n",
       "2024-09-30  61840.3418  2852.0  -7.1323  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Создадим новый DataFrame, который будет содержать ваши исходные данные OHLSW\n",
    "combined_df = df_final.copy()\n",
    "\n",
    "# Получаем все классы из tti.indicators, которые являются индикаторами\n",
    "indicator_classes = [cls for _, cls in inspect.getmembers(ti, inspect.isclass)]\n",
    "\n",
    "# Проходим по каждому индикатору и добавляем его данные в основной DataFrame\n",
    "for indicator_class in indicator_classes:\n",
    "    try:\n",
    "        # Инициализируем индикатор с вашим OHLSW DataFrame\n",
    "        indicator = indicator_class(input_data=df_final)\n",
    "        \n",
    "        # Получаем рассчитанные данные индикатора\n",
    "        indicator_data = indicator.getTiData()\n",
    "\n",
    "        # Присоединяем данные индикатора к основному DataFrame\n",
    "        # Примечание: добавляем как новые колонки (проверяем пересечение по индексам)\n",
    "        combined_df = combined_df.join(indicator_data, how='left')\n",
    "        \n",
    "        #print(f\"Добавлен индикатор: {indicator_class.__name__}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        #print(f\"Ошибка при вычислении {indicator_class.__name__}: {e}\")\n",
    "\n",
    "# Выводим объединённый DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adl</th>\n",
       "      <th>middle_band</th>\n",
       "      <th>upper_band</th>\n",
       "      <th>lower_band</th>\n",
       "      <th>cmf</th>\n",
       "      <th>...</th>\n",
       "      <th>vhf</th>\n",
       "      <th>vch</th>\n",
       "      <th>vosc</th>\n",
       "      <th>vrc</th>\n",
       "      <th>wc</th>\n",
       "      <th>ws</th>\n",
       "      <th>wad</th>\n",
       "      <th>wr</th>\n",
       "      <th>price_change</th>\n",
       "      <th>close_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>62465.0</td>\n",
       "      <td>67803.0</td>\n",
       "      <td>62060.0</td>\n",
       "      <td>66962.0</td>\n",
       "      <td>5.179793e+10</td>\n",
       "      <td>361902942122</td>\n",
       "      <td>61053.70</td>\n",
       "      <td>66929.4047</td>\n",
       "      <td>55177.9953</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>-11.2464</td>\n",
       "      <td>8.234233e+09</td>\n",
       "      <td>98.5535</td>\n",
       "      <td>65946.75</td>\n",
       "      <td>62896.2072</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>-9.4835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-12</th>\n",
       "      <td>62211.0</td>\n",
       "      <td>63362.0</td>\n",
       "      <td>58935.0</td>\n",
       "      <td>62392.0</td>\n",
       "      <td>3.200866e+10</td>\n",
       "      <td>325275499076</td>\n",
       "      <td>61108.35</td>\n",
       "      <td>67218.5053</td>\n",
       "      <td>54998.1947</td>\n",
       "      <td>-0.1120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5272</td>\n",
       "      <td>-19.7979</td>\n",
       "      <td>4.416763e+09</td>\n",
       "      <td>147.3988</td>\n",
       "      <td>61770.25</td>\n",
       "      <td>61879.7590</td>\n",
       "      <td>3457.0</td>\n",
       "      <td>-53.9312</td>\n",
       "      <td>-0.068248</td>\n",
       "      <td>62287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>60749.0</td>\n",
       "      <td>64500.0</td>\n",
       "      <td>60470.0</td>\n",
       "      <td>62287.0</td>\n",
       "      <td>3.387888e+10</td>\n",
       "      <td>307293674868</td>\n",
       "      <td>61285.85</td>\n",
       "      <td>67731.8764</td>\n",
       "      <td>54839.8236</td>\n",
       "      <td>-0.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3999</td>\n",
       "      <td>-24.7038</td>\n",
       "      <td>1.108212e+10</td>\n",
       "      <td>-0.9134</td>\n",
       "      <td>62386.00</td>\n",
       "      <td>61751.6988</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>-57.4512</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>60728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04</th>\n",
       "      <td>65603.0</td>\n",
       "      <td>65603.0</td>\n",
       "      <td>59954.0</td>\n",
       "      <td>60728.0</td>\n",
       "      <td>3.771114e+10</td>\n",
       "      <td>310622715799</td>\n",
       "      <td>61506.00</td>\n",
       "      <td>68361.5014</td>\n",
       "      <td>54650.4986</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>-20.0747</td>\n",
       "      <td>5.545745e+08</td>\n",
       "      <td>18.1436</td>\n",
       "      <td>61753.25</td>\n",
       "      <td>61617.8734</td>\n",
       "      <td>-4936.0</td>\n",
       "      <td>-64.3131</td>\n",
       "      <td>-0.025029</td>\n",
       "      <td>65664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>63146.0</td>\n",
       "      <td>66439.0</td>\n",
       "      <td>62812.0</td>\n",
       "      <td>65664.0</td>\n",
       "      <td>1.294871e+10</td>\n",
       "      <td>337999840733</td>\n",
       "      <td>61711.35</td>\n",
       "      <td>68705.9634</td>\n",
       "      <td>54716.7366</td>\n",
       "      <td>0.4622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>-23.6821</td>\n",
       "      <td>-4.098893e+09</td>\n",
       "      <td>-63.6838</td>\n",
       "      <td>65144.75</td>\n",
       "      <td>61840.3418</td>\n",
       "      <td>2852.0</td>\n",
       "      <td>-7.1323</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>63152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close        volume           adl  \\\n",
       "date                                                                         \n",
       "2024-10-16  62465.0  67803.0  62060.0  66962.0  5.179793e+10  361902942122   \n",
       "2024-10-12  62211.0  63362.0  58935.0  62392.0  3.200866e+10  325275499076   \n",
       "2024-10-08  60749.0  64500.0  60470.0  62287.0  3.387888e+10  307293674868   \n",
       "2024-10-04  65603.0  65603.0  59954.0  60728.0  3.771114e+10  310622715799   \n",
       "2024-09-30  63146.0  66439.0  62812.0  65664.0  1.294871e+10  337999840733   \n",
       "\n",
       "            middle_band  upper_band  lower_band     cmf  ...     vhf      vch  \\\n",
       "date                                                     ...                    \n",
       "2024-10-16     61053.70  66929.4047  55177.9953  0.1860  ...  0.4556 -11.2464   \n",
       "2024-10-12     61108.35  67218.5053  54998.1947 -0.1120  ...  0.5272 -19.7979   \n",
       "2024-10-08     61285.85  67731.8764  54839.8236 -0.1993  ...  0.3999 -24.7038   \n",
       "2024-10-04     61506.00  68361.5014  54650.4986 -0.0346  ...  0.4822 -20.0747   \n",
       "2024-09-30     61711.35  68705.9634  54716.7366  0.4622  ...  0.5498 -23.6821   \n",
       "\n",
       "                    vosc       vrc        wc          ws     wad       wr  \\\n",
       "date                                                                        \n",
       "2024-10-16  8.234233e+09   98.5535  65946.75  62896.2072  4902.0  -9.4835   \n",
       "2024-10-12  4.416763e+09  147.3988  61770.25  61879.7590  3457.0 -53.9312   \n",
       "2024-10-08  1.108212e+10   -0.9134  62386.00  61751.6988  1817.0 -57.4512   \n",
       "2024-10-04  5.545745e+08   18.1436  61753.25  61617.8734 -4936.0 -64.3131   \n",
       "2024-09-30 -4.098893e+09  -63.6838  65144.75  61840.3418  2852.0  -7.1323   \n",
       "\n",
       "            price_change  close_target  \n",
       "date                                    \n",
       "2024-10-16           NaN       62392.0  \n",
       "2024-10-12     -0.068248       62287.0  \n",
       "2024-10-08     -0.001683       60728.0  \n",
       "2024-10-04     -0.025029       65664.0  \n",
       "2024-09-30      0.081280       63152.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['price_change'] = combined_df['close'].pct_change()\n",
    "combined_df.sort_index(ascending=True)\n",
    "combined_df['close_target'] = combined_df['close'].shift(-1)\n",
    "combined_df = combined_df[:-1]\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RMSE\n",
    "* RMSLE\n",
    "* MAPE\n",
    "* PnL metric (1 if profit, -1 if loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest\n",
    "* GB's\n",
    "* NN's\n",
    "- (try bayesian optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.drop(['close', 'close_target'], axis=1)\n",
    "y = combined_df[\"close_target\"]\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                        StandardScaler())\n",
    "\n",
    "preproccessing_pipeline = ColumnTransformer([\n",
    "    ('num', numeric, num)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RandomForestRegressor RMSE: 5965.883092888658\n"
     ]
    }
   ],
   "source": [
    "errors_rf = []\n",
    "\n",
    "rf_model = make_pipeline(preproccessing_pipeline,\n",
    "                        RandomForestRegressor(random_state=42)\n",
    "                        )\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_rf)\n",
    "    errors_rf.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_rf)\n",
    "print(f'Average RandomForestRegressor RMSE: {r_mean_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = make_pipeline(preproccessing_pipeline,\n",
    "#                         RandomForestRegressor(random_state=42)\n",
    "#                         )\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# y_pred_rf = rf_model.predict(X_test)\n",
    "# print(root_mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average XGBoost RMSE: 3730.7471875256233\n"
     ]
    }
   ],
   "source": [
    "errors_xgb = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    xgb_model = make_pipeline(preproccessing_pipeline,\n",
    "                            xgb.XGBRegressor(\n",
    "                                objective='reg:squarederror',\n",
    "                                random_state=42\n",
    "                            ))\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_xgb)\n",
    "    errors_xgb.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_xgb)\n",
    "print(f'Average XGBoost RMSE: {r_mean_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = make_pipeline(preproccessing_pipeline,\n",
    "#                           xgb.XGBRegressor(objective='reg:squarederror',\n",
    "#                               random_state=42\n",
    "#                           ))\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "# y_pred_xgb = xgb_model.predict(X_test)\n",
    "# print(root_mean_squared_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CatBoost RMSE : 7670.239639801946\n"
     ]
    }
   ],
   "source": [
    "errors_cat = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    cat_model = make_pipeline(preproccessing_pipeline,\n",
    "                            CatBoostRegressor(\n",
    "                                loss_function='RMSE',\n",
    "                                random_state=42,\n",
    "                                verbose=0\n",
    "                            ))\n",
    "    \n",
    "    cat_model.fit(X_train, y_train)\n",
    "    y_pred_cat = cat_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_cat)\n",
    "    errors_cat.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_cat)\n",
    "print(f'Average CatBoost RMSE : {r_mean_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_model = make_pipeline(preproccessing_pipeline,\n",
    "#                           CatBoostRegressor(loss_function='RMSE',\n",
    "#                               random_state=42,\n",
    "#                               verbose=0\n",
    "#                           ))\n",
    "# cb_model.fit(X_train, y_train)\n",
    "# y_pred_cb = cb_model.predict(X_test)\n",
    "# print(root_mean_squared_error(y_test, y_pred_cb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 16, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 60597.937500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2077\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 61710.096774\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3053\n",
      "[LightGBM] [Info] Number of data points in the train set: 46, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 63092.500000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3997\n",
      "[LightGBM] [Info] Number of data points in the train set: 61, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 63263.836066\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4818\n",
      "[LightGBM] [Info] Number of data points in the train set: 76, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 59333.394737\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "Average LightGBM RMSE : 4037.7068775835955\n"
     ]
    }
   ],
   "source": [
    "errors_lgbm = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    lgbm_model = make_pipeline(preproccessing_pipeline,\n",
    "                                lgb.LGBMRegressor(\n",
    "                                objective='regression', \n",
    "                                random_state=42,\n",
    "                                max_bins=255,\n",
    "                                min_data_in_bin= 1,\n",
    "                                min_data_in_leaf=1,\n",
    "                                  # уменьшите это значение\n",
    "    ))\n",
    "    \n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_lgbm)\n",
    "    errors_lgbm.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_lgbm)\n",
    "print(f'Average LightGBM RMSE : {r_mean_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_model = make_pipeline(preproccessing_pipeline, \n",
    "#                            lgb.LGBMRegressor(\n",
    "#     objective='regression', \n",
    "#     learning_rate=0.1, \n",
    "#     n_estimators=100, \n",
    "#     num_leaves=31, \n",
    "#     random_state=42))\n",
    "\n",
    "# lgbm_model.fit(X_train, y_train)\n",
    "# y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "# print(root_mean_squared_error(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average GradientBoosting RMSE: 5254.835064710971\n"
     ]
    }
   ],
   "source": [
    "errors_grad_boost = []\n",
    "\n",
    "X_new = X.fillna(1)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    grad_boost_model = make_pipeline(preproccessing_pipeline,\n",
    "                                GradientBoostingRegressor(                         \n",
    "                                  random_state=42,\n",
    "    ))\n",
    "    \n",
    "  \n",
    "    grad_boost_model.fit(X_train, y_train)\n",
    "    y_pred_grad_boost = grad_boost_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_grad_boost)\n",
    "    errors_grad_boost.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_grad_boost)\n",
    "print(f'Average GradientBoosting RMSE: {r_mean_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ada RMSE: 5418.019110106931\n"
     ]
    }
   ],
   "source": [
    "errors_ada = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    ada_model = make_pipeline(preproccessing_pipeline,\n",
    "                                AdaBoostRegressor(\n",
    "                                estimator = DecisionTreeRegressor(max_depth=8),\n",
    "                                learning_rate = 0.1,\n",
    "                                random_state = 42)\n",
    "    )\n",
    "    \n",
    "    ada_model.fit(X_train, y_train)\n",
    "    y_pred_ada = ada_model.predict(X_test)\n",
    "    error = root_mean_squared_error(y_test, y_pred_ada)\n",
    "    errors_ada.append(error)\n",
    "\n",
    "r_mean_error = np.mean(errors_ada)\n",
    "print(f'Average Ada RMSE: {r_mean_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks (CHANGE THE DATA SPLITAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = combined_df.drop(['close', 'close_target'], axis=1)\n",
    "# y = combined_df[\"close_target\"]\n",
    "# #tscv = TimeSeriesSplit()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# preproccessing = ColumnTransformer([\n",
    "#     ('num', Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "#         ('scaler', StandardScaler())  # Scale numerical data\n",
    "#     ]), num)\n",
    "# ], remainder='passthrough')\n",
    "\n",
    "# X_train_processed = preproccessing.fit_transform(X_train)\n",
    "# X_test_processed = preproccessing.transform(X_test)\n",
    "\n",
    "# tf.random.set_seed(42)\n",
    "# nn_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(1, activation=\"linear\")  # Linear activation for regression\n",
    "# ])\n",
    "\n",
    "# adam_optimizer = AdamW(learning_rate=0.1)\n",
    "\n",
    "# # Use mean squared error for regression\n",
    "# nn_model.compile(loss=\"mean_squared_error\",\n",
    "#                  optimizer=adam_optimizer,\n",
    "#                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# history = nn_model.fit(X_train_processed, y_train, epochs=30, batch_size=8,\n",
    "#                        validation_data=(X_test_processed, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 3650553600.0000 - root_mean_squared_error: 60418.8945 - val_loss: 3968795904.0000 - val_root_mean_squared_error: 62998.3789\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3649643008.0000 - root_mean_squared_error: 60411.3555 - val_loss: 3967686400.0000 - val_root_mean_squared_error: 62989.5742\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3648480256.0000 - root_mean_squared_error: 60401.7305 - val_loss: 3966282496.0000 - val_root_mean_squared_error: 62978.4297\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3646931712.0000 - root_mean_squared_error: 60388.9102 - val_loss: 3964512768.0000 - val_root_mean_squared_error: 62964.3789\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3644932608.0000 - root_mean_squared_error: 60372.3555 - val_loss: 3962319616.0000 - val_root_mean_squared_error: 62946.9570\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3642414336.0000 - root_mean_squared_error: 60351.4961 - val_loss: 3959635200.0000 - val_root_mean_squared_error: 62925.6328\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3639304704.0000 - root_mean_squared_error: 60325.7266 - val_loss: 3956387072.0000 - val_root_mean_squared_error: 62899.8164\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3635532800.0000 - root_mean_squared_error: 60294.4570 - val_loss: 3952500224.0000 - val_root_mean_squared_error: 62868.9141\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3631021056.0000 - root_mean_squared_error: 60257.0312 - val_loss: 3947909120.0000 - val_root_mean_squared_error: 62832.3906\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3625693440.0000 - root_mean_squared_error: 60212.8086 - val_loss: 3942544640.0000 - val_root_mean_squared_error: 62789.6875\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3619476480.0000 - root_mean_squared_error: 60161.1602 - val_loss: 3936336640.0000 - val_root_mean_squared_error: 62740.2305\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3612290560.0000 - root_mean_squared_error: 60101.4062 - val_loss: 3929213184.0000 - val_root_mean_squared_error: 62683.4375\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3604058624.0000 - root_mean_squared_error: 60032.8828 - val_loss: 3921121536.0000 - val_root_mean_squared_error: 62618.8594\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3594708992.0000 - root_mean_squared_error: 59954.9609 - val_loss: 3912011776.0000 - val_root_mean_squared_error: 62546.0781\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3584175360.0000 - root_mean_squared_error: 59867.0469 - val_loss: 3901826048.0000 - val_root_mean_squared_error: 62464.5977\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3572393216.0000 - root_mean_squared_error: 59768.5625 - val_loss: 3890510080.0000 - val_root_mean_squared_error: 62373.9531\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3559305728.0000 - root_mean_squared_error: 59658.9766 - val_loss: 3878032640.0000 - val_root_mean_squared_error: 62273.8516\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3544860672.0000 - root_mean_squared_error: 59537.7852 - val_loss: 3864358400.0000 - val_root_mean_squared_error: 62163.9648\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3529015808.0000 - root_mean_squared_error: 59404.5664 - val_loss: 3849453056.0000 - val_root_mean_squared_error: 62043.9609\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3511736576.0000 - root_mean_squared_error: 59258.9492 - val_loss: 3833290752.0000 - val_root_mean_squared_error: 61913.5742\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3492989184.0000 - root_mean_squared_error: 59100.5508 - val_loss: 3815848960.0000 - val_root_mean_squared_error: 61772.5586\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3472736256.0000 - root_mean_squared_error: 58928.9531 - val_loss: 3797122048.0000 - val_root_mean_squared_error: 61620.7930\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3450959360.0000 - root_mean_squared_error: 58743.8828 - val_loss: 3777094144.0000 - val_root_mean_squared_error: 61458.0664\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3427646976.0000 - root_mean_squared_error: 58545.1172 - val_loss: 3755760128.0000 - val_root_mean_squared_error: 61284.2578\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3402788864.0000 - root_mean_squared_error: 58332.4297 - val_loss: 3733121280.0000 - val_root_mean_squared_error: 61099.2734\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3376387840.0000 - root_mean_squared_error: 58105.6797 - val_loss: 3709180416.0000 - val_root_mean_squared_error: 60903.0430\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3348450304.0000 - root_mean_squared_error: 57864.7734 - val_loss: 3683940096.0000 - val_root_mean_squared_error: 60695.4688\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3318984448.0000 - root_mean_squared_error: 57609.5938 - val_loss: 3657411584.0000 - val_root_mean_squared_error: 60476.5391\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3288007424.0000 - root_mean_squared_error: 57340.1016 - val_loss: 3629591552.0000 - val_root_mean_squared_error: 60246.0898\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3255543296.0000 - root_mean_squared_error: 57056.3086 - val_loss: 3600497664.0000 - val_root_mean_squared_error: 60004.1484\n",
      "Epoch 1/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 3791504128.0000 - root_mean_squared_error: 61574.8672 - val_loss: 4359291904.0000 - val_root_mean_squared_error: 66024.9375\n",
      "Epoch 2/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3789801216.0000 - root_mean_squared_error: 61561.0391 - val_loss: 4356096000.0000 - val_root_mean_squared_error: 66000.7266\n",
      "Epoch 3/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3787581184.0000 - root_mean_squared_error: 61542.9883 - val_loss: 4351068672.0000 - val_root_mean_squared_error: 65962.6328\n",
      "Epoch 4/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3783414016.0000 - root_mean_squared_error: 61509.1445 - val_loss: 4343736320.0000 - val_root_mean_squared_error: 65907.0312\n",
      "Epoch 5/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3782445824.0000 - root_mean_squared_error: 61501.2773 - val_loss: 4333620736.0000 - val_root_mean_squared_error: 65830.2422\n",
      "Epoch 6/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3770323200.0000 - root_mean_squared_error: 61402.6523 - val_loss: 4320244224.0000 - val_root_mean_squared_error: 65728.5625\n",
      "Epoch 7/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3760262912.0000 - root_mean_squared_error: 61320.6836 - val_loss: 4303101952.0000 - val_root_mean_squared_error: 65598.0312\n",
      "Epoch 8/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3747338240.0000 - root_mean_squared_error: 61215.2148 - val_loss: 4281738752.0000 - val_root_mean_squared_error: 65434.9961\n",
      "Epoch 9/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3731197952.0000 - root_mean_squared_error: 61083.2500 - val_loss: 4255792640.0000 - val_root_mean_squared_error: 65236.4375\n",
      "Epoch 10/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3711541760.0000 - root_mean_squared_error: 60922.1484 - val_loss: 4224997632.0000 - val_root_mean_squared_error: 64999.9805\n",
      "Epoch 11/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3688130304.0000 - root_mean_squared_error: 60729.7148 - val_loss: 4189148928.0000 - val_root_mean_squared_error: 64723.6367\n",
      "Epoch 12/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3660776960.0000 - root_mean_squared_error: 60504.1016 - val_loss: 4148116736.0000 - val_root_mean_squared_error: 64405.8750\n",
      "Epoch 13/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3629358336.0000 - root_mean_squared_error: 60243.9102 - val_loss: 4101807360.0000 - val_root_mean_squared_error: 64045.3555\n",
      "Epoch 14/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3593808896.0000 - root_mean_squared_error: 59948.1484 - val_loss: 4050144256.0000 - val_root_mean_squared_error: 63640.7422\n",
      "Epoch 15/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3554101248.0000 - root_mean_squared_error: 59616.0586 - val_loss: 3993186560.0000 - val_root_mean_squared_error: 63191.6641\n",
      "Epoch 16/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3510246912.0000 - root_mean_squared_error: 59247.1172 - val_loss: 3931008512.0000 - val_root_mean_squared_error: 62697.7539\n",
      "Epoch 17/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3462293760.0000 - root_mean_squared_error: 58841.0469 - val_loss: 3863691008.0000 - val_root_mean_squared_error: 62158.5938\n",
      "Epoch 18/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3411394304.0000 - root_mean_squared_error: 58406.9414 - val_loss: 3791366656.0000 - val_root_mean_squared_error: 61574.0742\n",
      "Epoch 19/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3354478848.0000 - root_mean_squared_error: 57917.6641 - val_loss: 3714232832.0000 - val_root_mean_squared_error: 60944.5078\n",
      "Epoch 20/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3294881280.0000 - root_mean_squared_error: 57400.8633 - val_loss: 3632467968.0000 - val_root_mean_squared_error: 60269.9609\n",
      "Epoch 21/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3231717120.0000 - root_mean_squared_error: 56848.0039 - val_loss: 3546290688.0000 - val_root_mean_squared_error: 59550.7422\n",
      "Epoch 22/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3165187840.0000 - root_mean_squared_error: 56259.8164 - val_loss: 3455973120.0000 - val_root_mean_squared_error: 58787.5234\n",
      "Epoch 23/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3095518464.0000 - root_mean_squared_error: 55637.1992 - val_loss: 3361842176.0000 - val_root_mean_squared_error: 57981.3945\n",
      "Epoch 24/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3022949376.0000 - root_mean_squared_error: 54981.1680 - val_loss: 3264163072.0000 - val_root_mean_squared_error: 57132.8555\n",
      "Epoch 25/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2947753472.0000 - root_mean_squared_error: 54293.0273 - val_loss: 3163252992.0000 - val_root_mean_squared_error: 56242.8047\n",
      "Epoch 26/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2872989952.0000 - root_mean_squared_error: 53600.0898 - val_loss: 3059401728.0000 - val_root_mean_squared_error: 55311.8594\n",
      "Epoch 27/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2790606848.0000 - root_mean_squared_error: 52826.0000 - val_loss: 2952986624.0000 - val_root_mean_squared_error: 54341.3906\n",
      "Epoch 28/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2709253376.0000 - root_mean_squared_error: 52050.2891 - val_loss: 2844394496.0000 - val_root_mean_squared_error: 53332.8633\n",
      "Epoch 29/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2626460928.0000 - root_mean_squared_error: 51248.8008 - val_loss: 2734004480.0000 - val_root_mean_squared_error: 52287.7070\n",
      "Epoch 30/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2542540544.0000 - root_mean_squared_error: 50423.3945 - val_loss: 2622230784.0000 - val_root_mean_squared_error: 51207.7227\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 3965967360.0000 - root_mean_squared_error: 62974.2383 - val_loss: 4118011136.0000 - val_root_mean_squared_error: 64171.7305\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3960227840.0000 - root_mean_squared_error: 62928.2500 - val_loss: 4107879424.0000 - val_root_mean_squared_error: 64092.7422\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3954430208.0000 - root_mean_squared_error: 62882.1719 - val_loss: 4090480896.0000 - val_root_mean_squared_error: 63956.8672\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3944505088.0000 - root_mean_squared_error: 62803.2148 - val_loss: 4062930432.0000 - val_root_mean_squared_error: 63741.1211\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3934455296.0000 - root_mean_squared_error: 62723.7031 - val_loss: 4022421760.0000 - val_root_mean_squared_error: 63422.5664\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3906486784.0000 - root_mean_squared_error: 62499.8359 - val_loss: 3966656768.0000 - val_root_mean_squared_error: 62981.3984\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3875851776.0000 - root_mean_squared_error: 62254.2969 - val_loss: 3893837312.0000 - val_root_mean_squared_error: 62400.6211\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3836230144.0000 - root_mean_squared_error: 61935.2852 - val_loss: 3802967808.0000 - val_root_mean_squared_error: 61668.2070\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3787073024.0000 - root_mean_squared_error: 61537.1992 - val_loss: 3693497344.0000 - val_root_mean_squared_error: 60774.1484\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3728090368.0000 - root_mean_squared_error: 61056.1094 - val_loss: 3565606656.0000 - val_root_mean_squared_error: 59712.6992\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3659231744.0000 - root_mean_squared_error: 60489.6172 - val_loss: 3420031488.0000 - val_root_mean_squared_error: 58481.0352\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3584705024.0000 - root_mean_squared_error: 59870.6172 - val_loss: 3257904384.0000 - val_root_mean_squared_error: 57078.0547\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3492687104.0000 - root_mean_squared_error: 59096.9727 - val_loss: 3080975616.0000 - val_root_mean_squared_error: 55506.5352\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3395891200.0000 - root_mean_squared_error: 58272.2305 - val_loss: 2891371264.0000 - val_root_mean_squared_error: 53771.4727\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3290904832.0000 - root_mean_squared_error: 57364.2578 - val_loss: 2691509504.0000 - val_root_mean_squared_error: 51879.7617\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3178526208.0000 - root_mean_squared_error: 56376.0977 - val_loss: 2484034048.0000 - val_root_mean_squared_error: 49840.0859\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3069036800.0000 - root_mean_squared_error: 55396.6562 - val_loss: 2271872256.0000 - val_root_mean_squared_error: 47664.1602\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2935381504.0000 - root_mean_squared_error: 54176.2148 - val_loss: 2058165760.0000 - val_root_mean_squared_error: 45367.0117\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2806693376.0000 - root_mean_squared_error: 52974.7852 - val_loss: 1846014848.0000 - val_root_mean_squared_error: 42965.2734\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2674748416.0000 - root_mean_squared_error: 51713.8516 - val_loss: 1638511872.0000 - val_root_mean_squared_error: 40478.5352\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2552037632.0000 - root_mean_squared_error: 50513.3320 - val_loss: 1438820864.0000 - val_root_mean_squared_error: 37931.7930\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2405750272.0000 - root_mean_squared_error: 49042.3828 - val_loss: 1249959680.0000 - val_root_mean_squared_error: 35354.7695\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2269405696.0000 - root_mean_squared_error: 47631.8984 - val_loss: 1074703872.0000 - val_root_mean_squared_error: 32782.6758\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2137798912.0000 - root_mean_squared_error: 46227.2773 - val_loss: 915501120.0000 - val_root_mean_squared_error: 30257.2500\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2007042176.0000 - root_mean_squared_error: 44789.0039 - val_loss: 774427968.0000 - val_root_mean_squared_error: 27828.5469\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1879823616.0000 - root_mean_squared_error: 43343.6055 - val_loss: 653049408.0000 - val_root_mean_squared_error: 25554.8320\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1757079040.0000 - root_mean_squared_error: 41901.5391 - val_loss: 552477632.0000 - val_root_mean_squared_error: 23504.8418\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1639643648.0000 - root_mean_squared_error: 40473.5117 - val_loss: 473294336.0000 - val_root_mean_squared_error: 21755.3281\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1528226176.0000 - root_mean_squared_error: 39070.1758 - val_loss: 415513376.0000 - val_root_mean_squared_error: 20384.1445\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1423396608.0000 - root_mean_squared_error: 37701.9297 - val_loss: 378596288.0000 - val_root_mean_squared_error: 19457.5508\n",
      "Epoch 1/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4031763456.0000 - root_mean_squared_error: 63496.0469 - val_loss: 1879393920.0000 - val_root_mean_squared_error: 43351.9766\n",
      "Epoch 2/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4026449664.0000 - root_mean_squared_error: 63454.1836 - val_loss: 1872049792.0000 - val_root_mean_squared_error: 43267.1914\n",
      "Epoch 3/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4014983936.0000 - root_mean_squared_error: 63363.7695 - val_loss: 1858154624.0000 - val_root_mean_squared_error: 43106.3164\n",
      "Epoch 4/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3994276864.0000 - root_mean_squared_error: 63200.1445 - val_loss: 1836028800.0000 - val_root_mean_squared_error: 42848.9062\n",
      "Epoch 5/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3964260096.0000 - root_mean_squared_error: 62962.1914 - val_loss: 1804431744.0000 - val_root_mean_squared_error: 42478.6016\n",
      "Epoch 6/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3914729472.0000 - root_mean_squared_error: 62567.5547 - val_loss: 1762681600.0000 - val_root_mean_squared_error: 41984.3008\n",
      "Epoch 7/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3852596224.0000 - root_mean_squared_error: 62068.9336 - val_loss: 1710552192.0000 - val_root_mean_squared_error: 41358.8242\n",
      "Epoch 8/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3774550016.0000 - root_mean_squared_error: 61436.8555 - val_loss: 1648207104.0000 - val_root_mean_squared_error: 40598.1172\n",
      "Epoch 9/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3680600064.0000 - root_mean_squared_error: 60667.1953 - val_loss: 1576380800.0000 - val_root_mean_squared_error: 39703.6641\n",
      "Epoch 10/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3571332352.0000 - root_mean_squared_error: 59759.5352 - val_loss: 1496187392.0000 - val_root_mean_squared_error: 38680.5820\n",
      "Epoch 11/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3447812864.0000 - root_mean_squared_error: 58716.5273 - val_loss: 1409223296.0000 - val_root_mean_squared_error: 37539.6211\n",
      "Epoch 12/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3311517184.0000 - root_mean_squared_error: 57543.6289 - val_loss: 1316795008.0000 - val_root_mean_squared_error: 36287.6719\n",
      "Epoch 13/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3164221696.0000 - root_mean_squared_error: 56248.4922 - val_loss: 1220615424.0000 - val_root_mean_squared_error: 34937.3086\n",
      "Epoch 14/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3007912192.0000 - root_mean_squared_error: 54840.5586 - val_loss: 1122475776.0000 - val_root_mean_squared_error: 33503.3711\n",
      "Epoch 15/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2844816896.0000 - root_mean_squared_error: 53331.7969 - val_loss: 1024085056.0000 - val_root_mean_squared_error: 32001.3281\n",
      "Epoch 16/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2671992576.0000 - root_mean_squared_error: 51685.7031 - val_loss: 927104320.0000 - val_root_mean_squared_error: 30448.3887\n",
      "Epoch 17/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2507618560.0000 - root_mean_squared_error: 50068.2109 - val_loss: 833030144.0000 - val_root_mean_squared_error: 28862.2617\n",
      "Epoch 18/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2330532096.0000 - root_mean_squared_error: 48266.3164 - val_loss: 743153536.0000 - val_root_mean_squared_error: 27260.8418\n",
      "Epoch 19/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2162465536.0000 - root_mean_squared_error: 46492.8242 - val_loss: 658636928.0000 - val_root_mean_squared_error: 25663.9219\n",
      "Epoch 20/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2009309312.0000 - root_mean_squared_error: 44811.9883 - val_loss: 580483136.0000 - val_root_mean_squared_error: 24093.2168\n",
      "Epoch 21/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1853568256.0000 - root_mean_squared_error: 43037.9023 - val_loss: 509046752.0000 - val_root_mean_squared_error: 22562.0645\n",
      "Epoch 22/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1705833088.0000 - root_mean_squared_error: 41284.8164 - val_loss: 444557440.0000 - val_root_mean_squared_error: 21084.5312\n",
      "Epoch 23/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1567264640.0000 - root_mean_squared_error: 39570.2812 - val_loss: 387150784.0000 - val_root_mean_squared_error: 19676.1484\n",
      "Epoch 24/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1438662656.0000 - root_mean_squared_error: 37910.1289 - val_loss: 336510464.0000 - val_root_mean_squared_error: 18344.2207\n",
      "Epoch 25/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1320479488.0000 - root_mean_squared_error: 36318.0742 - val_loss: 292132032.0000 - val_root_mean_squared_error: 17091.8711\n",
      "Epoch 26/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1212773632.0000 - root_mean_squared_error: 34804.2812 - val_loss: 253120448.0000 - val_root_mean_squared_error: 15909.7598\n",
      "Epoch 27/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1102994560.0000 - root_mean_squared_error: 33192.0938 - val_loss: 218480704.0000 - val_root_mean_squared_error: 14781.0928\n",
      "Epoch 28/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1016028544.0000 - root_mean_squared_error: 31856.5273 - val_loss: 187313072.0000 - val_root_mean_squared_error: 13686.2363\n",
      "Epoch 29/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 948599872.0000 - root_mean_squared_error: 30780.5879 - val_loss: 159585840.0000 - val_root_mean_squared_error: 12632.7285\n",
      "Epoch 30/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 877756480.0000 - root_mean_squared_error: 29609.5059 - val_loss: 135177168.0000 - val_root_mean_squared_error: 11626.5713\n",
      "Epoch 1/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3637519872.0000 - root_mean_squared_error: 60309.8359 - val_loss: 1342917248.0000 - val_root_mean_squared_error: 36645.8359\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3633357824.0000 - root_mean_squared_error: 60275.2031 - val_loss: 1334256512.0000 - val_root_mean_squared_error: 36527.4766\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3612466432.0000 - root_mean_squared_error: 60101.8711 - val_loss: 1316597504.0000 - val_root_mean_squared_error: 36284.9492\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3584197376.0000 - root_mean_squared_error: 59866.0039 - val_loss: 1286753024.0000 - val_root_mean_squared_error: 35871.3398\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3532011264.0000 - root_mean_squared_error: 59428.5820 - val_loss: 1243400960.0000 - val_root_mean_squared_error: 35261.8906\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3458922752.0000 - root_mean_squared_error: 58810.8359 - val_loss: 1186461440.0000 - val_root_mean_squared_error: 34445.0508\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3359892992.0000 - root_mean_squared_error: 57962.9141 - val_loss: 1116880000.0000 - val_root_mean_squared_error: 33419.7539\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3237506048.0000 - root_mean_squared_error: 56897.5391 - val_loss: 1036517952.0000 - val_root_mean_squared_error: 32194.9980\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3088566784.0000 - root_mean_squared_error: 55573.3086 - val_loss: 947588224.0000 - val_root_mean_squared_error: 30782.9219\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2922419456.0000 - root_mean_squared_error: 54058.0586 - val_loss: 852418752.0000 - val_root_mean_squared_error: 29196.2109\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2738953216.0000 - root_mean_squared_error: 52333.8477 - val_loss: 753736000.0000 - val_root_mean_squared_error: 27454.2520\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2547012608.0000 - root_mean_squared_error: 50466.8906 - val_loss: 654372992.0000 - val_root_mean_squared_error: 25580.7148\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2334429952.0000 - root_mean_squared_error: 48314.8594 - val_loss: 557012352.0000 - val_root_mean_squared_error: 23601.1094\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2121513728.0000 - root_mean_squared_error: 46058.5820 - val_loss: 464110656.0000 - val_root_mean_squared_error: 21543.2285\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1911368064.0000 - root_mean_squared_error: 43717.3867 - val_loss: 377787744.0000 - val_root_mean_squared_error: 19436.7617\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1695788160.0000 - root_mean_squared_error: 41177.3008 - val_loss: 299832736.0000 - val_root_mean_squared_error: 17315.6797\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1497099648.0000 - root_mean_squared_error: 38689.3828 - val_loss: 231653984.0000 - val_root_mean_squared_error: 15220.1836\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1296755712.0000 - root_mean_squared_error: 36004.9336 - val_loss: 173861072.0000 - val_root_mean_squared_error: 13185.6387\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1115498368.0000 - root_mean_squared_error: 33391.3789 - val_loss: 126471784.0000 - val_root_mean_squared_error: 11245.9678\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 949634240.0000 - root_mean_squared_error: 30805.8867 - val_loss: 89091960.0000 - val_root_mean_squared_error: 9438.8535\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 800639872.0000 - root_mean_squared_error: 28282.4395 - val_loss: 60697180.0000 - val_root_mean_squared_error: 7790.8394\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 669275072.0000 - root_mean_squared_error: 25854.0938 - val_loss: 40058256.0000 - val_root_mean_squared_error: 6329.1592\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 555558912.0000 - root_mean_squared_error: 23550.8887 - val_loss: 25842318.0000 - val_root_mean_squared_error: 5083.5342\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460495936.0000 - root_mean_squared_error: 21438.6582 - val_loss: 16713035.0000 - val_root_mean_squared_error: 4088.1580\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 378120128.0000 - root_mean_squared_error: 19420.3438 - val_loss: 11393913.0000 - val_root_mean_squared_error: 3375.4871\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 311776320.0000 - root_mean_squared_error: 17630.2480 - val_loss: 8771989.0000 - val_root_mean_squared_error: 2961.7544\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 261974400.0000 - root_mean_squared_error: 16161.8857 - val_loss: 7955030.5000 - val_root_mean_squared_error: 2820.4663\n",
      "Epoch 28/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 211857472.0000 - root_mean_squared_error: 14527.1484 - val_loss: 8255378.0000 - val_root_mean_squared_error: 2873.2173\n",
      "Epoch 29/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184475808.0000 - root_mean_squared_error: 13558.5039 - val_loss: 9202795.0000 - val_root_mean_squared_error: 3033.6108\n",
      "Epoch 30/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 155491232.0000 - root_mean_squared_error: 12442.2256 - val_loss: 10484335.0000 - val_root_mean_squared_error: 3237.9524\n"
     ]
    }
   ],
   "source": [
    "# TimeSeriesSplit для кросс-валидации\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Валидация на временных рядах\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Предобработка\n",
    "    X_train_processed = preproccessing_pipeline.fit_transform(X_train)\n",
    "    X_test_processed = preproccessing_pipeline.transform(X_test)\n",
    "    \n",
    "    # Построение и компиляция модели\n",
    "    nn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(400, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    \n",
    "    adam_optimizer = AdamW(learning_rate=0.01)\n",
    "    \n",
    "    nn_model.compile(loss=\"mean_squared_error\",\n",
    "                     optimizer = adam_optimizer,\n",
    "                     metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    # Обучение модели\n",
    "    history = nn_model.fit(X_train_processed, y_train, epochs=30, batch_size=8,\n",
    "                           validation_data=(X_test_processed, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TG integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEX integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Security"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
